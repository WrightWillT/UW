{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Gradient Descent </center>\n",
    "<center> Corinne Jones, TA </center>\n",
    "<center> DATA 558, Spring 2019 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we will discuss gradient descent and how to apply it to a simple function. After this lab, you should know the following:\n",
    "\n",
    "- How gradient descent works\n",
    "- How to choose a step size in gradient descent using two different methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Review\n",
    "Last week's introduction to Python included `for` loops and functions. For example, if we wanted to compute the Euclidean distance between two vectors, we could use the function below. The input `y` to the function is optional and the default value is (0,0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lines just tell the notebook to display all of the results.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(x, y=np.array([0,0])):\n",
    "  dist = np.sqrt(sum((x-y)**2))\n",
    "  return dist\n",
    "\n",
    "euclidean_distance(np.array([1,1]), np.array([2,1]))\n",
    "euclidean_distance(np.array([1,1]), np.array([0,0]))\n",
    "euclidean_distance(np.array([1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**\n",
    "Write a function called `linreg` that will compute the linear regression coefficients given a matrix $X$ of predictors and a vector $y$ of responses. I.e., write a function that given $X$ and $y$ will return $(X^TX)^{-1}X^Ty$. Hint: To compute $A^{-1}b$ for a matrix $A$ and vector $b$, you can use np.linalg.solve(A,b). \n",
    "\n",
    "Test your function using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(x_pred, y_resp):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some code to check your results\n",
    "import matplotlib.pyplot as plt\n",
    "# Create some data \n",
    "np.random.seed(0)\n",
    "X = np.random.normal(scale=2, size=(50, 1))\n",
    "X = np.hstack((np.ones_like(X), X))\n",
    "epsilon = np.random.normal(size=50)\n",
    "y = 1 + 2*X[:, 1] + epsilon\n",
    "\n",
    "# Get estimated betas from your function\n",
    "betas = linreg(X, y)\n",
    "print('Estimated betas =', betas)  # Are they close to (1, 2)?\n",
    "\n",
    "plt.scatter(X[:, 1], y)\n",
    "xs = np.arange(np.min(X[:, 1]), np.max(X[:, 1]), 0.1)\n",
    "plt.plot(xs, betas[0]+betas[1]*xs)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Regression line you fit to the data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Gradient Descent\n",
    "Gradient descent is one of the simplest methods to find a minimum of a function. Recall that the gradient of a differentiable function $f$ at a point $x$ is a vector pointing in the direction of greatest increase from $x$. Hence, when minimizing a function starting at some point $x_0$, it makes sense to repeatedly take steps in the direction of greatest decrease (the opposite direction of the gradient). In other words, we use the following scheme:\n",
    "\n",
    "> `Input:` $x_0$ (initial starting point)  \n",
    "> `While not converged:`  \n",
    ">  $ \\qquad x_k = x_{k-1} - t_{k}\\nabla f(x_{k-1})$  \n",
    "> `Output:` $x_K$ (where $K$ is the index of the final iteration)\n",
    "\n",
    "There are several ways to choose the step size $t_k$, two of which are described in detail later. One option is a constant step size, where the constant is chosen appropriately. The convergence criterion is typically taken to be that the norm of the gradient is sufficiently small.\n",
    "\n",
    "Another viewpoint of gradient descent is that at each step $k$ we're minimizing the following quadratic approximation to $f$ at $x_k$:\n",
    "$$f(x) \\approx f(x_k)+\\nabla f(x_k)^T(x-x_k)+\\frac{1}{2t_k}\\|x-x_k\\|^2.$$\n",
    "\n",
    "For linear regression $f$ will be our linear regression objective function. Let's try gradient descent on a simple example though first before applying it to linear regression. \n",
    "\n",
    "Consider the function $f(x_1, x_2) = x_1^2+x_2^2+x_1x_2$. We can obtain the gradient by differentiating with respect to $x_1$ and $x_2$:\n",
    "\\begin{align*}\n",
    "\\frac{\\partial f}{\\partial x_1} &= 2x_1+x_2\\\\\n",
    "\\frac{\\partial f}{\\partial x_2} &= 2x_2+x_1,\n",
    "\\end{align*}\n",
    "so\n",
    "\\begin{align*}\n",
    "\\nabla f(x_1,x_2) = \n",
    "\\begin{bmatrix}\n",
    "2x_1+x_2 \\\\\n",
    "2x_2+x_1\n",
    "\\end{bmatrix}.\n",
    "\\end{align*}\n",
    "\n",
    "Hence, since here $x=(x_1,x_2)$, the gradient descent update will be\n",
    "\\begin{align*}\n",
    "\\begin{bmatrix}\n",
    "x_{1,k} \\\\\n",
    "x_{2,k}\n",
    "\\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "x_{1, k-1} \\\\\n",
    "x_{2, k-1}\n",
    "\\end{bmatrix}\n",
    "-\n",
    "t_k \\begin{bmatrix}\n",
    "2x_{1,k-1}+x_{2,k-1} \\\\\n",
    "2x_{2,k-1}+x_{1,k-1}\n",
    "\\end{bmatrix}.\n",
    "\\end{align*}\n",
    "\n",
    "Let's code this now. We'll make the code fairly general so we can reuse it in the future. For illustration purposes I'm going to store all of the points we step to along the way, but in general you may not want to do this, as it slows down the algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**\n",
    "Write a function called `obj` that takes in a vector $x=[x_1, x_2]$ and returns the value of the objective function from above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3** Write a function called `grad` that takes in a vector $x=[x_1, x_2]$ and returns the gradient of the objective function from above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4** Fill in the gradient descent step in the function grad_descent below. (In this function I store the value of $x$ at each step for use later.)\n",
    "Check your functions using the plotting functions I provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_descent(x_init, t, eps=0.001, max_iter=1000):\n",
    "    \"\"\"\n",
    "    Run gradient descent with a fixed step size\n",
    "    Inputs:\n",
    "      - x_init: Starting point\n",
    "      - t: Step size (a constant)\n",
    "      - eps: Value for convergence criterion for the the norm of the gradient.\n",
    "      - max_iter: Maximum number of iterations to perform\n",
    "    Output:\n",
    "      - x_vals: Matrix of estimated x's at each iteration,\n",
    "                with the most recent values in the last row.\n",
    "    \"\"\"\n",
    "    x = x_init\n",
    "    grad_x = grad(x)\n",
    "    x_vals = [x]\n",
    "    iter = 0\n",
    "    while np.linalg.norm(grad_x) > eps and iter < max_iter:\n",
    "        # FILL IN THE GRADIENT DESCENT STEP HERE. It will update the variable x\n",
    "        # using the step size t and gradient grad_x.\n",
    "        \n",
    "        x_vals.append(x)\n",
    "        grad_x = grad(x)\n",
    "        iter += 1\n",
    "        \n",
    "    return np.array(x_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_plot(x_vals, xmin, xmax, ymin, ymax):\n",
    "    \"\"\"\n",
    "    Make a contour plot of the results\n",
    "    Inputs:\n",
    "      - x_vals: Locations the gradient descent algorithm stepped to\n",
    "      - xmin, xmax: x-axis limits\n",
    "      - ymin, ymax: y-axis limits\n",
    "    \"\"\"\n",
    "    # Check that the inputs are 2-dimensional\n",
    "    assert(x_vals.ndim == 2)\n",
    "    assert(x_vals.shape[1] == 2)\n",
    "    \n",
    "    # Create grid of values\n",
    "    x = np.linspace(xmin, xmax)\n",
    "    y = np.linspace(ymin, ymax)\n",
    "    grid = np.dstack(np.meshgrid(x,y)).reshape((-1, 2)).T\n",
    "    # Evaluate the objective function at each point on the grid\n",
    "    f = obj(grid)\n",
    "    # Make a contour plot of the function\n",
    "    plt.contour(x, y, f.reshape((len(x), len(y))))\n",
    "    plt.xlabel('$x_1$')\n",
    "    plt.ylabel('$x_2$')\n",
    "    plt.title('Gradient descent convergence', fontsize=16)\n",
    "    # Add the locations of the points the algorithm visited\n",
    "    jet = plt.get_cmap('jet')\n",
    "    colors = jet(np.linspace(0, 1, len(x_vals)))\n",
    "    plt.scatter(x_vals[:, 0], x_vals[:, 1], c=colors, marker='x')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convergence_plots(x_vals):\n",
    "    \"\"\"\n",
    "    Plot the convergence in terms of the function values and the gradients\n",
    "    Input:\n",
    "      - x_vals: Values the gradient descent algorithm stepped to\n",
    "    \"\"\"\n",
    "    n, d = x_vals.shape\n",
    "    fs = np.zeros(n)\n",
    "    grads = np.zeros((n, d))\n",
    "    for i in range(n):\n",
    "        fs[i] = obj(x_vals[i])\n",
    "        grads[i, :] = grad(x_vals[i])\n",
    "    grad_norms = np.linalg.norm(grads, axis=1)\n",
    "    plt.subplot(121)\n",
    "    plt.plot(fs)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Objective value')\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(grad_norms)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Norm of gradient')\n",
    "\n",
    "    plt.suptitle('Function Value and Norm of Gradient Convergence', fontsize=16)\n",
    "    plt.subplots_adjust(left=0.2, wspace=0.8, top=0.8)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to start at $(1, 0.5)$ and our convergence criterion is that $\\|\\nabla f(x)\\|<0.01$, then we can run our gradient descent function using the code below. We can also plot the results using a contour plot, since our function's inputs are two-dimensional. The more common plots of convergence are also included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_init = np.array([1, 0.5])\n",
    "t = 0.1\n",
    "x_vals = grad_descent(x_init, t, eps=0.01)\n",
    "\n",
    "# Make a contour plot with the results\n",
    "contour_plot(x_vals, -1.5, 1.5, -1.5, 1.5)\n",
    "\n",
    "# Make usual convergence plots\n",
    "convergence_plots(x_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5** What if we choose a much larger step size? Try running gradient descent with `t=10` and `max_iter=5`. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a contour plot with the results\n",
    "contour_plot(x_vals, min(x_vals[:, 0]), max(x_vals[:, 0]),  min(x_vals[:, 1]), max(x_vals[:, 1]))\n",
    "\n",
    "# Make usual convergence plots\n",
    "convergence_plots(x_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This brings us back to the question \"How can we choose an appropriate step size?\" There are many ways to do this, two of which I will explain:\n",
    "- Using the Lipschitz constant of the gradient, or an upper bound on it (assuming the gradient is indeed Lipschitz)\n",
    "- Performing backtracking line search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Constant step size\n",
    "We say that the gradient of a function $f$ is $L-$Lipschitz if\n",
    "$$\\|\\nabla f(x) - \\nabla f(x')\\| \\leq L\\|x-x'\\| \\text{ for all } x,x' \\text{ in the domain of } f.$$\n",
    "This is basically saying that the gradient doesn't change too quickly. If the function we're optimizing has a Lipschitz gradient, it turns out that $1/L$ is the optimal constant step size in gradient descent, where $L$ is the best (smallest) Lipschitz constant of the gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6&ast;** Show that the Lipschitz constant of the function from above is 3.\n",
    "\n",
    "&ast; denotes hard and/or time-consuming exercises that you can do later if you have time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try running gradient descent with this step size!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init = np.array([1,0.5])\n",
    "t = 1/3.0  # 1/Lipschitz constant\n",
    "x_vals = grad_descent(x_init, t, eps=0.01)\n",
    "contour_plot(x_vals, -1.5, 1.5, -1.5, 1.5)\n",
    "convergence_plots(x_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plots above we can see that it converges much faster when we provide the Lipschitz constant to the algorithm. But what if we don't know the Lipschitz constant or if the function doesn't have a Lipschitz gradient? In that case we can use a line search method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Inexact line search\n",
    "An alternative to using a constant step size is to use a line search method. The idea is that we know we want to move in the direction $-\\nabla f(x)$, but we don't know how far. Hence, we could systematically try some points in that direction and find one that will \"work\".\n",
    "\n",
    "One commonly used line search method is called backtracking line search. It works as follows. We start with some upper bound $t$ (say, $t=1$) on how far we are going to step in the direction of the gradient. We then check if this leads to a sufficient decrease in the objective function. Specifically, we check whether the following relation is satisfied:\n",
    "\\begin{align*}\n",
    "f(x-t\\nabla f(x)) < f(x) - \\alpha t \\|\\nabla f(x)\\|^2_2\n",
    "\\end{align*}\n",
    "for some parameter $\\alpha$. If $t$ doesn't work, then we decrease $t$ by a factor of $\\beta$ and check again. We repeat this until we find an appropriate $t$. We can take $\\alpha=1/2$ and $\\beta=1/2$, but in general we should have $\\alpha\\in(0,0.5]$ and $\\beta\\in(0,1)$. In picture form, we have something like Figure 1.\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "  <img src=\"https://www.researchgate.net/profile/Seyed_Ali_Asghar_Beheshti/publication/255581774/figure/fig1/AS:347196156334080@1459789422711/backtracking-line-search-The-curve-shows-f-restricted-to-the-line-over-which-we-search.ppm\" alt=\"\"/>\n",
    "    </center>\n",
    "  <figcaption><P>Figure 1. Backtracking line search. The black curve is $f$ as a function of $t$, i.e., $f$ restricted to the line on which we are searching. The lower dashed line is the linear approximation to $f$ at $x$, and the upper line has a smaller slope. The backtracking condition is that we find a $t$ such that $f(x-t\\nabla f(x))$ lies below the upper dashed line.</P></figcaption>\n",
    "</figure>\n",
    "\n",
    "Now we can code it. We need to change our original gradient descent algorithm to use backtracking line search instead of a constant step size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7** Insert the code for the sufficient decrease condition in the `bt_line_search` function below, along with the update to `t`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bt_line_search(x, t=1, alpha=0.5, beta=0.5, max_iter=100):\n",
    "    \"\"\"\n",
    "    Perform backtracking line search\n",
    "    Inputs:\n",
    "      - x: Current point\n",
    "      - t: Starting (maximum) step size\n",
    "      - alpha: Constant used to define sufficient decrease condition\n",
    "      - beta: Fraction by which we decrease t if the previous t doesn't work\n",
    "      - max_iter: Maximum number of iterations to run the algorithm\n",
    "    Output:\n",
    "      - t: Step size to use\n",
    "    \"\"\"\n",
    "    grad_x = grad(x)  # Gradient at x\n",
    "    norm_grad_x = np.linalg.norm(grad_x)  # Norm of the gradient at x\n",
    "    found_t = False\n",
    "    i = 0  # Iteration counter\n",
    "    while (found_t is False and i < max_iter):\n",
    "        # INSERT THE SUFFICIENT DECREASE CONDITION FOR BACKTRACKING LINE SEARCH IN THE\n",
    "        # if STATEMENT BELOW IN PLACE OF \"if True\".      \n",
    "        if True:\n",
    "            found_t = True\n",
    "        elif i == max_iter - 1:\n",
    "            raise('Maximum number of iterations of backtracking reached')\n",
    "        else:\n",
    "            t *= beta\n",
    "            i += 1\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8** Modify the gradient descent code below so it uses backtracking line search instead of a constant step size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_descent_bt(x_init, t_init=1, eps=0.001, max_iter=1000):\n",
    "    \"\"\"\n",
    "    Run gradient descent with a fixed step size\n",
    "    Inputs:\n",
    "      - x_init: Starting point\n",
    "      - t_init: Initial step size (a constant)\n",
    "      - eps: Value for convergence criterion for the the norm of the gradient.\n",
    "      - max_iter: Maximum number of iterations to perform\n",
    "    Output:\n",
    "      - x_vals: Matrix of estimated x's at each iteration,\n",
    "                with the most recent values in the last row.\n",
    "    \"\"\"\n",
    "    x = x_init\n",
    "    grad_x = grad(x)\n",
    "    x_vals = [x]\n",
    "    iter = 0\n",
    "    while np.linalg.norm(grad_x) > eps and iter < max_iter:\n",
    "        # CHANGE THE CODE BELOW SO IT USES BACKTRACKING LINE SEARCH INSTEAD OF A CONSTANT STEP SIZE\n",
    "        t = 1\n",
    "        x = x - t*grad_x\n",
    "        x_vals.append(x)\n",
    "        grad_x = grad(x)\n",
    "        iter += 1\n",
    "        \n",
    "    return np.array(x_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run our code, we get similar results as before, and it's also pretty fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = grad_descent_bt([1, 0.5], eps=0.01)\n",
    "contour_plot(x_vals, -1.5, 1.5, -1.5, 1.5)\n",
    "convergence_plots(x_vals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
