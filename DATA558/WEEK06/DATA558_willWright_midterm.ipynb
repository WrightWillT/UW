{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 558 Midterm\n",
    "\n",
    "Will Wright"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**  \n",
    "Compute the gradient $\\nabla F(\\beta)$ where the objective is:\n",
    "$$\\min_{\\mathbf{\\beta \\in \\mathbb{R}^d}} F(\\beta):=\\frac{1}{n}\\sum_{i=1}^{n} \\frac{1}{\\rho}log(1+exp(-\\rho y_ix_i^T\\beta)) + \\lambda\\lVert\\beta\\rVert_2^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**  \n",
    "Start by moving the scalar $\\frac{1}{\\rho}$ outside the summation:  \n",
    "$F(\\beta)=\\frac{1}{n\\rho}\\sum_{i=1}^{n} log(1+exp(-\\rho y_ix_i^T\\beta)) + \\lambda\\lVert\\beta\\rVert_2^2$\n",
    "\n",
    "Next, break up into two terms:  \n",
    "(1) $\\frac{1}{n\\rho}\\sum_{i=1}^{n} log(1+exp(-\\rho y_ix_i^T\\beta))$  \n",
    "(2) $\\lambda\\lVert \\beta\\rVert_2^2$ \n",
    "\n",
    "Find the derivative of the first term:  \n",
    "(1) $\\frac{\\partial}{\\partial \\beta}\\Big[\\frac{1}{n\\rho}\\sum_{i=1}^{n} log(1+exp(-\\rho y_ix_i^T\\beta))\\Big]$  \n",
    "  \n",
    "> Move the constant and summation to the outside of the derivative: \n",
    "$\\frac{1}{n\\rho}\\sum_{i=1}^{n}\\frac{\\partial}{\\partial \\beta}\\Big[ log(1+exp(-\\rho y_ix_i^T\\beta))\\Big]$ \n",
    "  \n",
    "> Use the chain rule with the following functions and their derivatives:  \n",
    "$(f\\circ g \\circ h) = log(g\\circ h)$  \n",
    "$(f\\circ g \\circ h)' = \\frac{1}{(g\\circ h)} \\cdot (g \\circ h)' $  \n",
    "$(g\\circ h) = 1+exp(-h)$  \n",
    "$(g\\circ h)' = -exp(-h)\\cdot h'$  \n",
    "$h = \\rho y_ix_i^T\\beta$  \n",
    "$h' = \\rho y_ix_i$  \n",
    "  \n",
    "> Putting the chains together, we have:  \n",
    "$(f\\circ g \\circ h)' = -\\rho y_ix_i \\cdot \\frac{exp(- \\rho y_ix_i^T\\beta)}{1+exp(-\\rho y_ix_i^T\\beta)}$\n",
    "  \n",
    "> Re-apply constant scalar and summation:  \n",
    "$=\\frac{1}{n\\rho}\\sum_{i=1}^{n}-\\rho y_ix_i \\cdot \\frac{exp(- \\rho y_ix_i^T\\beta)}{1+exp(-\\rho y_ix_i^T\\beta)}$\n",
    "\n",
    "> Move the constant $-\\rho$ outside the summation and cancel it out:\n",
    "$=-\\frac{1}{n}\\sum_{i=1}^{n}y_ix_i \\cdot \\frac{exp(- \\rho y_ix_i^T\\beta)}{1+exp(-\\rho y_ix_i^T\\beta)}$\n",
    "\n",
    "Next, derive the second term:  \n",
    "(2) $\\frac{\\partial}{\\partial \\beta}\\lambda\\lVert \\beta\\rVert_2^2$  \n",
    "  \n",
    "> Move the constant $\\lambda$ outside the derivation and convert to matrix form:  \n",
    "$ =\\lambda \\frac{\\partial}{\\partial \\beta}\\beta^T \\beta$\n",
    "  \n",
    "> Multiply by the identity matrix $I$:  \n",
    "$ =\\lambda \\frac{\\partial}{\\partial \\beta}\\beta^T I \\beta$\n",
    "  \n",
    "> Apply the property $\\frac{\\partial}{\\partial x}x^T Ax = (A+A^T)x$:  \n",
    "$ =\\lambda (I + I^T)\\beta$  \n",
    "  \n",
    "> Given that $(I + I^T)$ is simply a scalar of 2 for matrices, we can simplify:  \n",
    "\n",
    "> $=2\\lambda \\beta $  \n",
    "  \n",
    "Next, we add (1) and (2) to get:  \n",
    "$\\nabla F(\\beta) = -\\frac{1}{n}\\sum_{i=1}^{n}y_ix_i \\cdot \\frac{exp(- \\rho y_ix_i^T\\beta)}{1+exp(-\\rho y_ix_i^T\\beta)} + 2\\lambda \\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**  \n",
    "Consider the Spam dataset from The Elements of Statistical Learning. Standardize the data, if you have not done so already. Be sure to use the training and test splits from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "import scipy.linalg\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "spam = pd.read_table('https://web.stanford.edu/~hastie/ElemStatLearn/datasets/spam.data', \n",
    "                   delim_whitespace=True, header = None)\n",
    "test_indicator = pd.read_table('https://web.stanford.edu/~hastie/ElemStatLearn/datasets/spam.traintest',\n",
    "                         delim_whitespace=True, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(spam)[:, 0:-1]\n",
    "y = np.asarray(spam)[:, -1]*2 - 1\n",
    "test_indicator = np.array(test_indicator).T[0]\n",
    "\n",
    "# Divide the data into train, test sets\n",
    "x_train = x[test_indicator == 0, :]\n",
    "x_test = x[test_indicator == 1, :]\n",
    "y_train = y[test_indicator == 0]\n",
    "y_test = y[test_indicator == 1]\n",
    "\n",
    "# Standardize the data.\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# Keep track of the number of samples and dimension of each sample\n",
    "n_train = len(y_train)\n",
    "n_test = len(y_test)\n",
    "d = np.size(x, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**  \n",
    "Write a function _myrhologistic_ that implements the accelerated gradient algorithm to train the $\\ell_2^2$-regularized binary logistic regression with $\\rho$-logistic loss. The function takes as input\n",
    "the initial step-size for the backtracking rule, the $\\epsilon$ for the stopping criterion based on the norm of the gradient of the objective, and the value of $\\rho$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subroutines for myrhologistic to call:\n",
    "\n",
    "# rho logistic gradient\n",
    "def computegrad(beta, lamb, rho, x, y):\n",
    "    yx = y[:, np.newaxis]*x\n",
    "    denom = 1+np.exp(-rho*yx.dot(beta))\n",
    "    grad = -1/len(y)*np.sum(yx*np.exp(-rho*yx.dot(beta[:, np.newaxis]))/\n",
    "        denom[:, np.newaxis], axis=0) + 2*lamb*beta\n",
    "    return grad\n",
    "\n",
    "# rho logistic objective\n",
    "def computeobj(beta, lamb, rho, x, y):\n",
    "    return 1/len(y) * np.sum(1/rho*np.log(1 + np.exp(-rho*y*x.dot(beta)))) + lamb*np.linalg.norm(beta)**2\n",
    "\n",
    "# backtracking with rho logistic\n",
    "def backtracking(beta, lamb, rho, x, y, eta, alpha=0.5, gamma=0.8):\n",
    "    grad_beta = computegrad(beta, lamb, rho, x, y)\n",
    "    norm_grad_beta = np.linalg.norm(grad_beta)\n",
    "    found_eta = False\n",
    "    iter = 0\n",
    "    while found_eta == False:\n",
    "        if computeobj(beta - eta * grad_beta, lamb, rho, x, y) < \\\n",
    "            computeobj(beta, lamb, rho, x, y)- alpha * eta * norm_grad_beta ** 2:\n",
    "                found_eta = True\n",
    "        else:\n",
    "            eta *= gamma\n",
    "            iter += 1\n",
    "    return eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEtaInit(x, y, lamb):\n",
    "    eta_init = 1/(scipy.linalg.eigh(1/len(y)*x.T.dot(x),\n",
    "                                eigvals=(d-1, d-1),\n",
    "                                eigvals_only=True)[0]+lamb)\n",
    "    return eta_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myrhologistic(x, y, beta_init, theta_init, lamduh, rho, eta_init, eps):\n",
    "    beta = beta_init\n",
    "    theta = theta_init\n",
    "    eta = eta_init\n",
    "    grad_theta = computegrad(theta, lamb, rho, x, y)\n",
    "    grad_beta = computegrad(beta, lamb, rho, x, y)\n",
    "    beta_vals = beta\n",
    "    theta_vals = theta\n",
    "    iter = 0\n",
    "    while np.linalg.norm(grad_beta) > eps:\n",
    "        eta = backtracking(theta, lamb, rho, x, y, eta)\n",
    "        beta_new = theta - eta*grad_theta\n",
    "        theta = beta_new + iter/(iter+3)*(beta_new-beta)\n",
    "        beta_vals = np.vstack((beta_vals, beta))\n",
    "        theta_vals = np.vstack((theta_vals, theta))\n",
    "        grad_theta = computegrad(theta, lamb, rho, x, y)\n",
    "        grad_beta = computegrad(beta, lamb, rho, x, y)\n",
    "        beta = beta_new\n",
    "        iter += 1\n",
    "    return beta_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**  \n",
    "Train your $\\ell_2^2$-regularized binary logistic regression with $\\rho$-logistic loss with $\\rho=2$ and $\\epsilon=10^{-3}$ o the Spam dataset for $\\lambda=1$. Report your misclassification error for this value of $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters\n",
    "rho = 2\n",
    "eps = 10**-3\n",
    "lamb = 1\n",
    "beta_init = np.zeros(d)\n",
    "theta_init = np.zeros(d)\n",
    "eta_init = computeEtaInit(x_train, y_train, lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_betas = myrhologistic(x_train, y_train, beta_init, theta_init, lamb, rho, eta_init, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_opt = train_betas[-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(x, y, beta):\n",
    "    y_pred = 1/(1+np.exp(-x.dot(beta))) > 0.5\n",
    "    y_pred = y_pred*2 - 1 # Convert to +/- 1\n",
    "    return np.mean(y_pred != y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09526916802610114"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_error(x_train, y_train, beta_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**  \n",
    "Write a function _crossval_ that implements leave-one-out cross-validation and hold-out cross-validation. You may either write a function that implements each variant separately depending on the case, or write a general cross-validation function that can be instantiated in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loocv(x, y, lamb, rho, eps):\n",
    "    n, d = x.shape\n",
    "    beta_init = np.zeros(d)\n",
    "    theta_init = np.zeros(d)\n",
    "    errors = []\n",
    "    for i in range(n):\n",
    "        x_loo = np.vstack((x[0:i,:],x[(i+1):,:]))\n",
    "        y_loo = np.concatenate([y[0:i],y[(i+1):]])\n",
    "        eta_init = computeEtaInit(x_loo, y_loo, lamb)\n",
    "        loo_betas = myrhologistic(x_loo, y_loo, beta_init, theta_init, lamb, rho, eta_init, eps)\n",
    "        loo_beta_opt = loo_betas[-1,:]\n",
    "        errors.append(compute_error(x_train, y_train, loo_beta_opt))\n",
    "    return np.sum(errors)/n\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hocv(x, y, lamb, eps, rho, test_size = 0.2):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = test_size)\n",
    "    d = x_train.shape[1]\n",
    "    beta_init = np.zeros(d)\n",
    "    theta_init = np.zeros(d)\n",
    "    eta_init = computeEtaInit(x_train, y_train, lamb)\n",
    "    ho_betas = myrhologistic(x_train, y_train, beta_init, theta_init, lamb, rho, eta_init, eps)\n",
    "    ho_beta_opt = ho_betas[-1,:]\n",
    "    error = compute_error(x_test, y_test, ho_beta_opt)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**  \n",
    "Find the optimal value of $\\lambda$ using leave-one-out cross-validation.  Find the optimal value of $\\lambda$ useing hold-out cross-validation with a 80%/20% split for the training set/testing set.  Report your misclassification errors for the two values of $\\lambda$ found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb_vals = []\n",
    "for i in range(-3,3):\n",
    "    lamb_vals.append(10**i) # testing very small to very large\n",
    "# lamb_vals.extend(np.linspace(0,2,21)) # after seeing 1 be optimal, testing values around 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lamb_opt(x, y, lamb_vals, eps, rho, method, test_size = 0.2):\n",
    "    if method=='loocv':\n",
    "        errors = []\n",
    "        for lamb in lamb_vals:\n",
    "            error = loocv(x, y, lamb, rho, eps)\n",
    "            errors.append(error)\n",
    "        minpos = errors.index(min(errors))\n",
    "        lamb_opt = lamb_vals[minpos]\n",
    "        return lamb_opt\n",
    "    if method=='hocv':\n",
    "        errors = []\n",
    "        for lamb in lamb_vals:\n",
    "            error = hocv(x, y, lamb, eps, rho, test_size)\n",
    "            errors.append(error)\n",
    "        minpos = errors.index(min(errors))\n",
    "        lamb_opt = lamb_vals[minpos]\n",
    "        return lamb_opt\n",
    "    else:\n",
    "        print('Unknown method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "loocv_lamb_opt = compute_lamb_opt(x_train, y_train, lamb_vals, eps, rho, method = 'loocv')\n",
    "loocv_error = loocv(x_train, y_train, loocv_lamb_opt, rho, eps)\n",
    "print('Leave-one-out optimal lambda is: ',loocv_lamb_opt)\n",
    "print('Leave-one-out misclassification rate: ',loocv_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/20 Hold-out optimal lambda is:  0.1\n",
      "80/20 Hold-out misclassification rate:  0.0\n"
     ]
    }
   ],
   "source": [
    "hocv_lamb_opt = compute_lamb_opt(x_train, y_train, lamb_vals, eps, rho, method = 'hocv')\n",
    "hocv_error = hocv(x_train, y_train, hocv_lamb_opt, eps, rho, test_size = 0.2)\n",
    "print('80/20 Hold-out optimal lambda is: ',hocv_lamb_opt)\n",
    "print('80/20 Hold-out misclassification rate: ',hocv_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 - Data Competition Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**  \n",
    "Pick two classes of your choice from the dataset. Train a classifier using $\\ell_2^2$-regularized binary\n",
    "logistic regression with $\\rho$-logistic loss on the training set using your own accelerated gradient algorithm with $\\rho = 2$, $\\epsilon = 10^{âˆ’3}$, and $\\lambda = 1$. Be sure to use the features you previously generated with the provided script rather than the raw image features. Plot, with different colors, the misclassification error on the training set and on the validation set vs iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (if on Windows)\n",
    "# x_train = np.load('C:/Users/Will/Documents/data_competition1_files/train_features.npy')\n",
    "# y_train = np.load('C:/Users/Will/Documents/data_competition1_files/train_labels.npy')\n",
    "# x_val = np.load('C:/Users/Will/Documents/data_competition1_files/val_features.npy')\n",
    "# y_val = np.load('C:/Users/Will/Documents/data_competition1_files/val_labels.npy')\n",
    "\n",
    "# Load data (if on Mac)\n",
    "x_train_raw = np.load('/Users/willwright/Downloads/data_competition1_files/train_features.npy')\n",
    "y_train_raw = np.load('/Users/willwright/Downloads/data_competition1_files/train_labels.npy')\n",
    "x_val_raw = np.load('/Users/willwright/Downloads/data_competition1_files/val_features.npy')\n",
    "y_val_raw = np.load('/Users/willwright/Downloads/data_competition1_files/val_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset of data (selecting group 5 and 9)\n",
    "class1 = 5\n",
    "class2 = 9\n",
    "train_ids = np.array([np.where(y_train_raw==class1),np.where(y_train_raw==class2)]).reshape(-1)\n",
    "x_train = x_train_raw[train_ids]\n",
    "y_train = y_train_raw[train_ids]\n",
    "val_ids = np.array([np.where(y_val_raw==class1),np.where(y_val_raw==class2)]).reshape(-1)\n",
    "x_val = x_val_raw[val_ids]\n",
    "y_val = y_val_raw[val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change indicators from the original classes to +1/-1\n",
    "y_train[y_train==class1] = 1\n",
    "y_train[y_train==class2] = -1\n",
    "y_val[y_val==class1] = 1\n",
    "y_val[y_val==class2] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize\n",
    "x_standardizer = preprocessing.StandardScaler()\n",
    "x_train = x_standardizer.fit_transform(x_train)\n",
    "x_val = x_standardizer.fit_transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "n, d = x_train.shape\n",
    "rho = 2\n",
    "eps = 10**-3\n",
    "lamb = 1\n",
    "beta_init = np.zeros(d)\n",
    "theta_init = np.zeros(d)\n",
    "eta_init = computeEtaInit(x_train, y_train, lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "kaggle_betas = myrhologistic(x_train, y_train, beta_init, theta_init, lamb, rho, eta_init, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_misclassification_errors(x_train, y_train, x_val, y_val, betas):\n",
    "    iterations = betas.shape[0]\n",
    "    train_errors = []\n",
    "    val_errors = []\n",
    "    for i in range(iterations):\n",
    "        train_error = compute_error(x_train, y_train, betas[i,:])\n",
    "        train_errors.append(train_error)\n",
    "        val_error = compute_error(x_val, y_val, betas[i,:])\n",
    "        val_errors.append(val_error)\n",
    "    plt.plot(train_errors, color = \"blue\")\n",
    "    plt.plot(val_errors, color = \"red\")\n",
    "    plt.ylabel(\"Misclassification Rate\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.title(\"Misclassification Rates by Iteration\")\n",
    "    plt.legend([\"Training Data\", \"Validation Data\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot misclassification error on the training set by iteration\n",
    "plot_misclassification_errors(x_train, y_train, x_val, y_val, kaggle_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Misclassificaiton Rate:  0.001\n",
      "Validation Misclassificaiton Rate:  0.005\n"
     ]
    }
   ],
   "source": [
    "print('Training Misclassificaiton Rate: ',compute_error(x_train, y_train, kaggle_betas[-1,:]))\n",
    "print('Validation Misclassificaiton Rate: ',compute_error(x_val, y_val, kaggle_betas[-1,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**  \n",
    "Find the value of the regularization parameter $\\lambda$ using using leave-one-out cross-validation. Find the value of the regularization parameter $\\lambda$ using using hold-out cross-validation. Train a classifier using $\\ell_2^2$-regularized binary logistic regression with $\\rho$-logistic loss on the training set using your own accelerated gradient algorithm with that value of $\\lambda$ found by hold-out cross-validation. Plot, with different colors, the misclassification error on the training set and on the validation set vs. iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loocv_lamb_opt = compute_lamb_opt(x_train, y_train, lamb_vals, eps, rho, method = 'loocv')\n",
    "loocv_error = loocv(x_train, y_train, loocv_lamb_opt, rho, eps)\n",
    "print('Leave-one-out optimal lambda is: ',loocv_lamb_opt)\n",
    "print('Leave-one-out misclassification rate: ',loocv_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with ideal lambda, as computed by LOOCV\n",
    "loocv_lamb_opt_betas = myrhologistic(x_train, y_train, beta_init, theta_init, locv_lamb_opt, rho, eta_init, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_misclassification_errors(x_train, y_train, x_val, y_val, loocv_lamb_opt_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Misclassificaiton Rate: ',compute_error(x_train, y_train, loocv_lamb_opt_betas[-1,:]))\n",
    "print('Validation Misclassificaiton Rate: ',compute_error(x_val, y_val, loocv_lamb_opt_betas[-1,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/20 Hold-out optimal lambda is:  0.001\n",
      "80/20 Hold-out misclassification rate:  0.015\n"
     ]
    }
   ],
   "source": [
    "hocv_lamb_opt = compute_lamb_opt(x_train, y_train, lamb_vals, eps, rho, method = 'hocv')\n",
    "hocv_error = hocv(x_train, y_train, hocv_lamb_opt, eps, rho, test_size = 0.2)\n",
    "print('80/20 Hold-out optimal lambda is: ',hocv_lamb_opt)\n",
    "print('80/20 Hold-out misclassification rate: ',hocv_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with ideal lambda, as computed by HOCV\n",
    "hocv_lamb_opt_betas = myrhologistic(x_train, y_train, beta_init, theta_init, hocv_lamb_opt, rho, eta_init, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_misclassification_errors(x_train, y_train, x_val, y_val, hocv_lamb_opt_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Misclassificaiton Rate:  0.001\n",
      "Validation Misclassificaiton Rate:  0.005\n"
     ]
    }
   ],
   "source": [
    "print('Training Misclassificaiton Rate: ',compute_error(x_train, y_train, hocv_lamb_opt_betas[-1,:]))\n",
    "print('Validation Misclassificaiton Rate: ',compute_error(x_val, y_val, hocv_lamb_opt_betas[-1,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**  \n",
    "Consider all pairs of classes from the dataset. For each pair of classes, train a classifier using\n",
    "a $\\ell_2^2$-regularized binary logistic regression with $\\rho$-logistic loss on the training set comprising\n",
    "only the data-points for that pair of classes using your own fast gradient algorithm. For each\n",
    "pair of classes, find the value of the regularization parameter $\\lambda$ using hold-out cross-validation\n",
    "on the training set comprising only the data-points for that pair of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_possibilities = np.unique(y_train_raw)\n",
    "n_classes = len(class_possibilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator as op\n",
    "from functools import reduce\n",
    "\n",
    "def ncr(n, r):\n",
    "    r = min(r, n-r)\n",
    "    numer = reduce(op.mul, range(n, n-r, -1), 1)\n",
    "    denom = reduce(op.mul, range(1, r+1), 1)\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_pairs = int(ncr(n_classes, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs = np.zeros((possible_pairs,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1.])"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "j = 1\n",
    "all_pairs[i,:] = i\n",
    "all_pairs[i,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-522-52348eaa20c9>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-522-52348eaa20c9>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    for j in range(possible_pairs:\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for i in range(possible_pairs):\n",
    "    all_pairs[i,:]\n",
    "    for j in range(possible_pairs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "(0, 1)\n",
      "(0, 2)\n",
      "(0, 3)\n",
      "(0, 4)\n",
      "(0, 5)\n",
      "(0, 6)\n",
      "(0, 7)\n",
      "(0, 8)\n",
      "(0, 9)\n",
      "(1, 0)\n",
      "(1, 1)\n",
      "(1, 2)\n",
      "(1, 3)\n",
      "(1, 4)\n",
      "(1, 5)\n",
      "(1, 6)\n",
      "(1, 7)\n",
      "(1, 8)\n",
      "(1, 9)\n",
      "(2, 0)\n",
      "(2, 1)\n",
      "(2, 2)\n",
      "(2, 3)\n",
      "(2, 4)\n",
      "(2, 5)\n",
      "(2, 6)\n",
      "(2, 7)\n",
      "(2, 8)\n",
      "(2, 9)\n",
      "(3, 0)\n",
      "(3, 1)\n",
      "(3, 2)\n",
      "(3, 3)\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "(3, 6)\n",
      "(3, 7)\n",
      "(3, 8)\n",
      "(3, 9)\n",
      "(4, 0)\n",
      "(4, 1)\n",
      "(4, 2)\n",
      "(4, 3)\n",
      "(4, 4)\n",
      "(4, 5)\n",
      "(4, 6)\n",
      "(4, 7)\n",
      "(4, 8)\n",
      "(4, 9)\n",
      "(5, 0)\n",
      "(5, 1)\n",
      "(5, 2)\n",
      "(5, 3)\n",
      "(5, 4)\n",
      "(5, 5)\n",
      "(5, 6)\n",
      "(5, 7)\n",
      "(5, 8)\n",
      "(5, 9)\n",
      "(6, 0)\n",
      "(6, 1)\n",
      "(6, 2)\n",
      "(6, 3)\n",
      "(6, 4)\n",
      "(6, 5)\n",
      "(6, 6)\n",
      "(6, 7)\n",
      "(6, 8)\n",
      "(6, 9)\n",
      "(7, 0)\n",
      "(7, 1)\n",
      "(7, 2)\n",
      "(7, 3)\n",
      "(7, 4)\n",
      "(7, 5)\n",
      "(7, 6)\n",
      "(7, 7)\n",
      "(7, 8)\n",
      "(7, 9)\n",
      "(8, 0)\n",
      "(8, 1)\n",
      "(8, 2)\n",
      "(8, 3)\n",
      "(8, 4)\n",
      "(8, 5)\n",
      "(8, 6)\n",
      "(8, 7)\n",
      "(8, 8)\n",
      "(8, 9)\n",
      "(9, 0)\n",
      "(9, 1)\n",
      "(9, 2)\n",
      "(9, 3)\n",
      "(9, 4)\n",
      "(9, 5)\n",
      "(9, 6)\n",
      "(9, 7)\n",
      "(9, 8)\n",
      "(9, 9)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "iterables = [class_possibilities, class_possibilities]\n",
    "\n",
    "for t in itertools.product(*iterables):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**  \n",
    "Write a function that for any new data point predicts its label. To do this, you will perform the following: input the data point into each classifier (for each pair of classes) you trained above. Record the class predicted by each classifier. Then your prediction for this data point is the most frequently predicted class. If there is a tie, randomly choose between the tied classes. Report the misclassification error on the validation set and test set. Report the precision/recall on the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
