{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA558 - Data Competition Report\n",
    "***\n",
    "Will Wright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "import scipy.linalg\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from random import sample\n",
    "from random import choice\n",
    "import sklearn.linear_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import seaborn as sn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # suppress conversion warnings\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 3 - Exercise 4\n",
    "Read the announcement “Data Competition, Part 1” released on Canvas. We strongly recommend you perform this task on AWS. You will use your own $\\ell_2^2$_-regularized logistic regression_ for this exercise. After completing this exercise, submit your predictions to the data competition Kaggle website.  \n",
    "  \n",
    "Download the data for the Kaggle competition. Run the script extract features.py to extract features from the images. This script was written in Python 3 and depends on the library PyTorch.  \n",
    "\n",
    "Pick two classes of your choice from the dataset. Train an $\\ell_2^2$_-regularized logistic regression_ classifier on the training set using your own fast gradient algorithm with $\\lambda$ = 1. Be sure to use the features you generated above rather than the raw image features. Plot, with different colors, the _misclassification error_ on the training set and on the validation set vs iterations.  \n",
    "\n",
    "Find the value of the regularization parameter $\\lambda$ using cross-validation; you may use scikit-learn’s built-in functions for this purpose. Train an $\\ell_2^2$_-regularized logistic regression_ classifier on the training set using your own fast gradient algorithm with that value of $\\lambda$ found by cross-validation. Plot, with different colors, the misclassification error on the training set and on the validation set vs iterations.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 4 - Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Pick two classes of your choice from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.decomposition import PCA\n",
    "import copy\n",
    "\n",
    "# Load data\n",
    "x_train = np.load('C:/Users/Will/Documents/data_competition1_files/train_features.npy')\n",
    "y_train = np.load('C:/Users/Will/Documents/data_competition1_files/train_labels.npy')\n",
    "x_val = np.load('C:/Users/Will/Documents/data_competition1_files/val_features.npy')\n",
    "y_val = np.load('C:/Users/Will/Documents/data_competition1_files/val_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset of data (selecting group 5 and 9)\n",
    "class1 = 5\n",
    "class2 = 9\n",
    "train_ids = np.array([np.where(y_train==class1),np.where(y_train==class2)]).reshape(-1)\n",
    "x_train = x_train[train_ids]\n",
    "y_train = y_train[train_ids]\n",
    "val_ids = np.array([np.where(y_val==class1),np.where(y_val==class2)]).reshape(-1)\n",
    "x_val = x_val[val_ids]\n",
    "y_val = y_val[val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data and update labels to +/- 1\n",
    "x_train = preprocessing.scale(x_train).T\n",
    "x_val = preprocessing.scale(x_val).T\n",
    "y_train = y_train.T\n",
    "y_train[y_train==class1] = 1\n",
    "y_train[y_train==class2] = -1\n",
    "y_val = y_val.T\n",
    "y_val[y_val==class1] = 1\n",
    "y_val[y_val==class2] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Run PCA on this subset of the data using Scikit-Learn and project the data down to two dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PCA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-69ddadc83dd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# PCA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvd_solver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'full'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The first principle component:\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nThe second principle component:\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PCA' is not defined"
     ]
    }
   ],
   "source": [
    "# PCA\n",
    "pca = PCA(svd_solver='full')\n",
    "pca = pca.fit(x_train.T)\n",
    "print(\"The first principle component:\\n\", pca.components_[0])\n",
    "print(\"\\nThe second principle component:\\n\", pca.components_[1])\n",
    "\n",
    "# Project subset data down to two dimensions\n",
    "x_train_2 = np.array([pca.components_[0],pca.components_[1]]).dot(x_train)\n",
    "x_val_2 = np.array([pca.components_[0],pca.components_[1]]).dot(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) You will be training an $l_2$-regularized logistic regression classifier.  Find the value of the regularization paramater $\\lambda$ using Scikit-Learn with 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e2ae29eddee5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Find optimal lambda by 5-fold cross-validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegressionCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10e-8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlamb_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train_2' is not defined"
     ]
    }
   ],
   "source": [
    "# Find optimal lambda by 5-fold cross-validation\n",
    "n = x_train_2.shape[1]\n",
    "clf = LogisticRegressionCV(cv=5, penalty='l2', fit_intercept=False, tol=10e-8, max_iter=1000)\n",
    "fit = clf.fit(x_train_2.T, y_train)\n",
    "lamb_opt = 1/(2*n*clf.C_[0])\n",
    "print(\"The optimal value of lambda is\", lamb_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computegrad(X, y, beta, lam = 0.05):\n",
    "    'Output grad(F) given X, y, beta, and lambda'\n",
    "    ## calc the nxn p-matrix\n",
    "    # start with the diagonal of non-zeros\n",
    "    n, d = X.shape\n",
    "    P_diag = [0 for x in range(n)] # P is nxn\n",
    "    for i in range(0,n):\n",
    "        yXTbeta = y[i]*(X[i,:].T).dot(beta) # 1x1 * dx1 * 1xd = 1x1\n",
    "        P_diag[i] = 1-(np.exp(yXTbeta))/(1+np.exp(yXTbeta)) \n",
    "    P = np.diagflat(P_diag) # nxn\n",
    "    emp_risk = (-1/n)*(X.T.dot(P).dot(y.reshape(n,1))) # (dxn * nxn) = dxn; dxn * nx1 = dx1\n",
    "    penalty = 2*lam*beta.reshape(d,1) # dx1\n",
    "    grad_F = emp_risk + penalty #dx1 + dx1 = dx1\n",
    "    return grad_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeobj(X, y, beta, lam = 0.05):\n",
    "    'Output F (objective is to minimize) for any given X, y, beta, lam'\n",
    "    n = X.shape[0]\n",
    "    sum_terms = [0 for i in range(n)] # initialize list\n",
    "    for i in range(0, n):\n",
    "        sum_terms[i] = np.log(1+np.exp(-y[i]*X[i,:].T.dot(beta)))\n",
    "    avg_summation = sum(sum_terms)/n\n",
    "    regularization = lam*np.sum(beta**2)\n",
    "    F = avg_summation + regularization\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtracking(X, y, beta, eta, alpha = 0.5, gamma = 0.8):\n",
    "    'Output new eta for a given X, y, beta, eta, alpha, and gamma'\n",
    "    grad = computegrad(X,y,beta)\n",
    "    complete = False\n",
    "    while complete == False:\n",
    "        if computeobj(X, y, beta - eta*grad) < computeobj(X, y, beta) - alpha*eta*np.linalg.norm(grad)**2:\n",
    "            complete = True\n",
    "        else:\n",
    "            eta = eta * gamma\n",
    "    return eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eta(X, lam = 0.05):\n",
    "    'returns initial step-size based on equation provided in lecture notes'\n",
    "    eigenValues, eigenVectors = np.linalg.eig((1/len(X)) * X.T.dot(X))\n",
    "    L = max(eigenValues) + lam\n",
    "    return 1/L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastgradalgo(X, y, eta, target = 10e-4, lam = 0.05):\n",
    "    # initialize lists of betas, Fs, and grad(F)s\n",
    "    # identical to standard gradient descent except theta is added and used in the computegrad subroutine\n",
    "    beta = np.zeros((X.shape[1],1))\n",
    "    theta = np.zeros((X.shape[1],1))\n",
    "    betas = [beta] #start with the first beta included\n",
    "    Fs = [computeobj(X,y,beta,lam)] # start with the first F included\n",
    "    grad = computegrad(X,y,theta,lam)\n",
    "    t=0\n",
    "    while (np.linalg.norm(grad) > target):\n",
    "        eta = backtracking(X, y, beta, eta)\n",
    "        beta_prior = copy.copy(beta)\n",
    "        beta = theta - eta * computegrad(X, y, theta, lam)\n",
    "        theta = beta + (t/(t+3))*(beta - beta_prior)\n",
    "        betas.append(beta)\n",
    "        F = computeobj(X, y, beta, lam)\n",
    "        Fs.append(F) \n",
    "        grad = computegrad(X, y, theta, lam)\n",
    "        t += 1\n",
    "    return np.array(betas) #, np.array(Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrowed this objective function and the obj_plot below since I can't get mine to work\n",
    "def obj(X, Y, beta, lamb):\n",
    "    n = X.shape[1]\n",
    "    return 1/n*np.sum(np.log(1+np.exp(np.multiply(-Y.T,X.T.dot(beta))))) + lamb*np.linalg.norm(beta)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_plot(X1, Y1, X2, Y2, vals, lam, dim):\n",
    "    n = vals.shape[0] # number of iterations\n",
    "    obj1 = np.zeros(n)\n",
    "    obj2 = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        obj1[i] = obj(X1, Y1, vals[i],lam)\n",
    "        obj2[i] = obj(X2, Y2, vals[i],lam)\n",
    "    plt.figure()\n",
    "    plt.plot(obj1, label='Training Set')\n",
    "    plt.plot(obj2, label='Validation Set')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Objective Value')\n",
    "    plt.title('Objective Value over Iterations\\nDimension = %d' %dim, fontsize=13)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on the training set\n",
    "vals_fg = fastgradalgo(x_train_2.T, y_train, compute_eta(x_train_2), lam=lamb_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot objective values over iterations\n",
    "obj_plot(x_train_2, y_train, x_val_2, y_val, vals_fg, lamb_opt, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Repeat steps b-d, trying all power of two up to the number of features in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Plot, with different colors, the misclassification error on the training set and on the test set vs. the dimension of the projection. Note that to obtain the performance on the test set you will need to submit to Kaggle, and you can only submit three times per day. If you only have enough tiem for three submissions, submit your predictions for dimensions 2, 16, 128."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midterm - Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subroutines for myrhologistic to call:\n",
    "\n",
    "# rho logistic gradient\n",
    "def computegrad(beta, lamb, rho, x, y):\n",
    "    yx = y[:, np.newaxis]*x\n",
    "    denom = 1+np.exp(-rho*yx.dot(beta))\n",
    "    grad = -1/len(y)*np.sum(yx*np.exp(-rho*yx.dot(beta[:, np.newaxis]))/\n",
    "        denom[:, np.newaxis], axis=0) + 2*lamb*beta\n",
    "    return grad\n",
    "\n",
    "# rho logistic objective\n",
    "def computeobj(beta, lamb, rho, x, y):\n",
    "    return 1/len(y) * np.sum(1/rho*np.log(1 + np.exp(-rho*y*x.dot(beta)))) + lamb*np.linalg.norm(beta)**2\n",
    "\n",
    "# backtracking with rho logistic\n",
    "def backtracking(beta, lamb, rho, x, y, eta, alpha=0.5, gamma=0.8):\n",
    "    grad_beta = computegrad(beta, lamb, rho, x, y)\n",
    "    norm_grad_beta = np.linalg.norm(grad_beta)\n",
    "    found_eta = False\n",
    "    iter = 0\n",
    "    while found_eta == False:\n",
    "        if computeobj(beta - eta * grad_beta, lamb, rho, x, y) < \\\n",
    "            computeobj(beta, lamb, rho, x, y)- alpha * eta * norm_grad_beta ** 2:\n",
    "                found_eta = True\n",
    "        else:\n",
    "            eta *= gamma\n",
    "            iter += 1\n",
    "    return eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEtaInit(x, y, lamb):\n",
    "    eta_init = 1/(scipy.linalg.eigh(1/len(y)*x.T.dot(x),\n",
    "                                eigvals=(d-1, d-1),\n",
    "                                eigvals_only=True)[0]+lamb)\n",
    "    return eta_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myrhologistic(x, y, beta_init, theta_init, lamb, rho, eta_init, eps):\n",
    "    beta = beta_init\n",
    "    theta = theta_init\n",
    "    eta = eta_init\n",
    "    grad_theta = computegrad(theta, lamb, rho, x, y)\n",
    "    grad_beta = computegrad(beta, lamb, rho, x, y)\n",
    "    beta_vals = beta\n",
    "    theta_vals = theta\n",
    "    iter = 0\n",
    "    while np.linalg.norm(grad_beta) > eps:\n",
    "        eta = backtracking(theta, lamb, rho, x, y, eta)\n",
    "        beta_new = theta - eta*grad_theta\n",
    "        theta = beta_new + iter/(iter+3)*(beta_new-beta)\n",
    "        beta_vals = np.vstack((beta_vals, beta))\n",
    "        theta_vals = np.vstack((theta_vals, theta))\n",
    "        grad_theta = computegrad(theta, lamb, rho, x, y)\n",
    "        grad_beta = computegrad(beta, lamb, rho, x, y)\n",
    "        beta = beta_new\n",
    "        iter += 1\n",
    "    return beta_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(x, y, beta):\n",
    "    y_pred = 1/(1+np.exp(-x.dot(beta))) > 0.5\n",
    "    y_pred = y_pred*2 - 1 # Convert to +/- 1\n",
    "    return np.mean(y_pred != y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loocv(x, y, lamb, rho, eps):\n",
    "    n, d = x.shape\n",
    "    beta_init = np.zeros(d)\n",
    "    theta_init = np.zeros(d)\n",
    "    errors = []\n",
    "    for i in tqdm(range(n)):\n",
    "        x_loo = np.vstack((x[0:i,:],x[(i+1):,:]))\n",
    "        y_loo = np.concatenate([y[0:i],y[(i+1):]])\n",
    "        eta_init = computeEtaInit(x_loo, y_loo, lamb)\n",
    "        loo_betas = myrhologistic(x_loo, y_loo, beta_init, theta_init, lamb, rho, eta_init, eps)\n",
    "        loo_beta_opt = loo_betas[-1,:]\n",
    "        errors.append(compute_error(x_train, y_train, loo_beta_opt))\n",
    "    return np.sum(errors)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hocv(x, y, lamb, eps, rho, test_size = 0.2):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = test_size)\n",
    "    d = x_train.shape[1]\n",
    "    beta_init = np.zeros(d)\n",
    "    theta_init = np.zeros(d)\n",
    "    eta_init = computeEtaInit(x_train, y_train, lamb)\n",
    "    ho_betas = myrhologistic(x_train, y_train, beta_init, theta_init, lamb, rho, eta_init, eps)\n",
    "    ho_beta_opt = ho_betas[-1,:]\n",
    "    error = compute_error(x_test, y_test, ho_beta_opt)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb_vals = []\n",
    "for i in range(-3,3):\n",
    "    lamb_vals.append(10**i) # testing very small to very large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lamb_opt(x, y, lamb_vals, eps, rho, method, test_size = 0.2):\n",
    "    if method=='loocv':\n",
    "        errors = []\n",
    "        for lamb in lamb_vals:\n",
    "            error = loocv(x, y, lamb, rho, eps)\n",
    "            errors.append(error)\n",
    "        minpos = errors.index(min(errors))\n",
    "        lamb_opt = lamb_vals[minpos]\n",
    "        return lamb_opt\n",
    "    if method=='hocv':\n",
    "        errors = []\n",
    "        for lamb in lamb_vals:\n",
    "            error = hocv(x, y, lamb, eps, rho, test_size)\n",
    "            errors.append(error)\n",
    "        minpos = errors.index(min(errors))\n",
    "        lamb_opt = lamb_vals[minpos]\n",
    "        return lamb_opt\n",
    "    else:\n",
    "        print('Unknown method')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**  \n",
    "Pick two classes of your choice from the dataset. Train a classifier using $\\ell_2^2$-regularized binary\n",
    "logistic regression with $\\rho$-logistic loss on the training set using your own accelerated gradient algorithm with $\\rho = 2$, $\\epsilon = 10^{−3}$, and $\\lambda = 1$. Be sure to use the features you previously generated with the provided script rather than the raw image features. Plot, with different colors, the misclassification error on the training set and on the validation set vs iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (if on Windows)\n",
    "# x_train = np.load('C:/Users/Will/Documents/data_competition1_files/train_features.npy')\n",
    "# y_train = np.load('C:/Users/Will/Documents/data_competition1_files/train_labels.npy')\n",
    "# x_val = np.load('C:/Users/Will/Documents/data_competition1_files/val_features.npy')\n",
    "# y_val = np.load('C:/Users/Will/Documents/data_competition1_files/val_labels.npy')\n",
    "\n",
    "# Load data (if on Mac)\n",
    "x_train_raw = np.load('/Users/willwright/Downloads/data_competition1_files/train_features.npy')\n",
    "y_train_raw = np.load('/Users/willwright/Downloads/data_competition1_files/train_labels.npy')\n",
    "x_val_raw = np.load('/Users/willwright/Downloads/data_competition1_files/val_features.npy')\n",
    "y_val_raw = np.load('/Users/willwright/Downloads/data_competition1_files/val_labels.npy')\n",
    "x_test_raw = np.load('/Users/willwright/Downloads/data_competition1_files/test_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset of data (selecting group 5 and 9)\n",
    "class1 = 5\n",
    "class2 = 9\n",
    "train_ids = np.array([np.where(y_train_raw==class1),np.where(y_train_raw==class2)]).reshape(-1)\n",
    "x_train = x_train_raw.copy()[train_ids]\n",
    "y_train = y_train_raw.copy()[train_ids]\n",
    "val_ids = np.array([np.where(y_val_raw==class1),np.where(y_val_raw==class2)]).reshape(-1)\n",
    "x_val = x_val_raw.copy()[val_ids]\n",
    "y_val = y_val_raw.copy()[val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change indicators from the original classes to +1/-1\n",
    "y_train[y_train==class1] = 1\n",
    "y_train[y_train==class2] = -1\n",
    "y_val[y_val==class1] = 1\n",
    "y_val[y_val==class2] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize\n",
    "x_standardizer = preprocessing.StandardScaler()\n",
    "x_train = x_standardizer.fit_transform(x_train)\n",
    "x_val = x_standardizer.fit_transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "n, d = x_train.shape\n",
    "rho = 2\n",
    "eps = 10**-3\n",
    "lamb = 1\n",
    "beta_init = np.zeros(d)\n",
    "theta_init = np.zeros(d)\n",
    "eta_init = computeEtaInit(x_train, y_train, lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "kaggle_betas = myrhologistic(x_train, y_train, beta_init, theta_init, lamb, rho, eta_init, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_misclassification_errors(x_train, y_train, x_val, y_val, betas):\n",
    "    iterations = betas.shape[0]\n",
    "    train_errors = []\n",
    "    val_errors = []\n",
    "    for i in range(iterations):\n",
    "        train_error = compute_error(x_train, y_train, betas[i,:])\n",
    "        train_errors.append(train_error)\n",
    "        val_error = compute_error(x_val, y_val, betas[i,:])\n",
    "        val_errors.append(val_error)\n",
    "    plt.plot(train_errors, color = \"blue\")\n",
    "    plt.plot(val_errors, color = \"red\")\n",
    "    plt.ylabel(\"Misclassification Rate\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.title(\"Misclassification Rates by Iteration\")\n",
    "    plt.legend([\"Training Data\", \"Validation Data\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot misclassification error on the training set by iteration\n",
    "plot_misclassification_errors(x_train, y_train, x_val, y_val, kaggle_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Misclassificaiton Rate: ',compute_error(x_train, y_train, kaggle_betas[-1,:]))\n",
    "print('Validation Misclassificaiton Rate: ',compute_error(x_val, y_val, kaggle_betas[-1,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**  \n",
    "Find the value of the regularization parameter $\\lambda$ using using leave-one-out cross-validation. Find the value of the regularization parameter $\\lambda$ using using hold-out cross-validation. Train a classifier using $\\ell_2^2$-regularized binary logistic regression with $\\rho$-logistic loss on the training set using your own accelerated gradient algorithm with that value of $\\lambda$ found by hold-out cross-validation. Plot, with different colors, the misclassification error on the training set and on the validation set vs. iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loocv_lamb_opt = compute_lamb_opt(x_train, y_train, lamb_vals, eps, rho, method = 'loocv')\n",
    "loocv_error = loocv(x_train, y_train, loocv_lamb_opt, rho, eps)\n",
    "print('Leave-one-out optimal lambda is: ',loocv_lamb_opt)\n",
    "print('Leave-one-out misclassification rate: ',loocv_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is taking multiple days to run so I'm going to take a sub-sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train_index = sample(list(range(len(x_train))),50)\n",
    "x_train_sample = x_train.copy()[sample_train_index]\n",
    "y_train_sample = y_train.copy()[sample_train_index]\n",
    "sample_val_index = sample(list(range(len(x_val))),50)\n",
    "x_val_sample = x_val.copy()[sample_val_index]\n",
    "y_val_sample = y_val.copy()[sample_val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loocv_lamb_opt = compute_lamb_opt(x_train_sample, y_train_sample, lamb_vals, eps, rho, method = 'loocv')\n",
    "loocv_error = loocv(x_train_sample, y_train_sample, loocv_lamb_opt, rho, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Leave-one-out optimal lambda is: ',loocv_lamb_opt)\n",
    "print('Leave-one-out misclassification rate: ',loocv_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with ideal lambda, as computed by LOOCV\n",
    "loocv_lamb_opt_betas = myrhologistic(x_train_sample, y_train_sample, \n",
    "                                     beta_init, theta_init, loocv_lamb_opt, rho, eta_init, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_misclassification_errors(x_train_sample, y_train_sample, x_val_sample, y_val_sample, loocv_lamb_opt_betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could be due to the sub-sampling, but it's certainly suspicious. Why would there be no change until the 3rd iteration when it snaps perfectly to 0%??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Misclassificaiton Rate: ',compute_error(x_train_sample, y_train_sample, loocv_lamb_opt_betas[-1,:]))\n",
    "print('Validation Misclassificaiton Rate: ',compute_error(x_val_sample, y_val_sample, loocv_lamb_opt_betas[-1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hocv_lamb_opt = compute_lamb_opt(x_train, y_train, lamb_vals, eps, rho, method = 'hocv')\n",
    "hocv_error = hocv(x_train, y_train, hocv_lamb_opt, eps, rho, test_size = 0.2)\n",
    "print('80/20 Hold-out optimal lambda is: ',hocv_lamb_opt)\n",
    "print('80/20 Hold-out misclassification rate: ',hocv_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with ideal lambda, as computed by HOCV\n",
    "hocv_lamb_opt_betas = myrhologistic(x_train, y_train, beta_init, theta_init, hocv_lamb_opt, rho, eta_init, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_misclassification_errors(x_train, y_train, x_val, y_val, hocv_lamb_opt_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Misclassificaiton Rate: ',compute_error(x_train, y_train, hocv_lamb_opt_betas[-1,:]))\n",
    "print('Validation Misclassificaiton Rate: ',compute_error(x_val, y_val, hocv_lamb_opt_betas[-1,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an _obscenely_ good misclassification rate. Too good, perhaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**  \n",
    "Consider all pairs of classes from the dataset. For each pair of classes, train a classifier using\n",
    "a $\\ell_2^2$-regularized binary logistic regression with $\\rho$-logistic loss on the training set comprising\n",
    "only the data-points for that pair of classes using your own fast gradient algorithm. For each\n",
    "pair of classes, find the value of the regularization parameter $\\lambda$ using hold-out cross-validation\n",
    "on the training set comprising only the data-points for that pair of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_possibilities = np.unique(y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create array of all possible pairs\n",
    "all_pairs = np.empty((0,2),int)\n",
    "for i in class_possibilities:\n",
    "    for j in class_possibilities:\n",
    "        all_pairs = np.append(all_pairs, \n",
    "                              np.array([class_possibilities[i],class_possibilities[j]]).reshape(1,2), \n",
    "                              axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_index = []\n",
    "for i in range(len(all_pairs)):\n",
    "    # remove pairs with same class\n",
    "    if all_pairs[i,0] != all_pairs[i,1]:\n",
    "        # remove pairs already in the array higher up, but in different order\n",
    "        if any(([all_pairs[i,1],all_pairs[i,0]] == x).all() for x in list(all_pairs[0:i-1]))==False:\n",
    "            keep_index.append(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs = all_pairs[keep_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas_opt = []\n",
    "models = []\n",
    "for i in tqdm(range(len(all_pairs))):\n",
    "    # Subset to pair\n",
    "    class1, class2 = all_pairs[i]\n",
    "    train_ids = np.array([np.where(y_train_raw==class1),np.where(y_train_raw==class2)]).reshape(-1)\n",
    "    x_train = x_train_raw[train_ids]\n",
    "    y_train = y_train_raw[train_ids]\n",
    "    val_ids = np.array([np.where(y_val_raw==class1),np.where(y_val_raw==class2)]).reshape(-1)\n",
    "    x_val = x_val_raw[val_ids]\n",
    "    y_val = y_val_raw[val_ids]\n",
    "    # Replace class indicators with +/-1; make sure to set -1 to avoid converting all values to 1 (if the class2 is 1)\n",
    "    y_train[y_train==class2] = -1\n",
    "    y_train[y_train==class1] = 1\n",
    "    y_val[y_val==class2] = -1\n",
    "    y_val[y_val==class1] = 1\n",
    "    # Standardize\n",
    "    x_standardizer = preprocessing.StandardScaler()\n",
    "    x_train = x_standardizer.fit_transform(x_train)\n",
    "    x_val = x_standardizer.fit_transform(x_val)\n",
    "    # Calculate optimal lambda\n",
    "    hocv_lamb_opt = compute_lamb_opt(x_train, y_train, lamb_vals, eps, rho, method = 'hocv')\n",
    "    lambdas_opt.append(hocv_lamb_opt)\n",
    "    # train model with optimal lambda\n",
    "    betas = myrhologistic(x_train, \n",
    "                          y_train, \n",
    "                          beta_init, \n",
    "                          theta_init, \n",
    "                          lambdas_opt[i], \n",
    "                          rho, \n",
    "                          computeEtaInit(x_train, y_train, lambdas_opt[i]), \n",
    "                          eps)\n",
    "    betas_opt = betas[-1]\n",
    "    models.append(betas_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**  \n",
    "Write a function that for any new data point predicts its label. To do this, you will perform the following: input the data point into each classifier (for each pair of classes) you trained above. Record the class predicted by each classifier. Then your prediction for this data point is the most frequently predicted class. If there is a tie, randomly choose between the tied classes. Report the misclassification error on the validation set and test set. Report the precision/recall on the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prediction(x, y, beta):\n",
    "    y_pred = 1/(1+np.exp(-x.dot(beta))) > 0.5 \n",
    "    y_pred = y_pred*2 - 1 # Convert to +/- 1\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set train/validation/test to total dataset\n",
    "x_train = x_train_raw.copy()\n",
    "y_train = y_train_raw.copy()\n",
    "x_val = x_val_raw.copy()\n",
    "y_val = y_val_raw.copy()\n",
    "x_test = x_test_raw.copy()\n",
    "\n",
    "# Standardize\n",
    "x_standardizer = preprocessing.StandardScaler()\n",
    "x_train = x_standardizer.fit_transform(x_train)\n",
    "x_val = x_standardizer.fit_transform(x_val)\n",
    "x_test = x_standardizer.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training set predictions and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = np.zeros((len(y_train),len(models)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_train)):\n",
    "    for j in range(len(models)):\n",
    "        train_predictions[i,j] = compute_prediction(x_train[i], y_train[i], models[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from +/-1 to the original class \n",
    "for i in range(train_predictions.shape[0]):\n",
    "    for j in range(train_predictions.shape[1]):\n",
    "        if train_predictions[i,j]==1:\n",
    "            train_predictions[i,j]=all_pairs[j,0]\n",
    "        else:\n",
    "            train_predictions[i,j]=all_pairs[j,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countX(lst, x): \n",
    "    return lst.count(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each data point, pick either the most occurring prediction by all the classifiers or, if tie, random between\n",
    "# the tied classes\n",
    "train_prediction_results = []\n",
    "for i in range(len(train_predictions)):\n",
    "    freq = []\n",
    "    for j in class_possibilities:\n",
    "        freq.append(countX(list(train_predictions[i]),class_possibilities[j]))\n",
    "    prediction = class_possibilities[choice([k for k,x in enumerate(freq) if x==max(freq)])]\n",
    "    train_prediction_results.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = []\n",
    "for i in class_possibilities:\n",
    "    freq.append(countX(train_prediction_results,class_possibilities[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results\n",
    "pd.DataFrame({'Class': class_possibilities, 'Freq': freq})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misclassification on the test set\n",
    "print('Training Misclassificaiton Rate: ',np.mean(train_prediction_results != y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_conf_matrix = confusion_matrix(y_train, train_prediction_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = train_conf_matrix\n",
    "df_cm = pd.DataFrame(array, index = class_possibilities,\n",
    "                  columns = class_possibilities)\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt = 'g')# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fscore, support = precision_recall_fscore_support(y_train, train_prediction_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Class': class_possibilities,\n",
    "             'Training Pecision': precision,\n",
    "             'Training Recall': recall,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = np.zeros((len(y_val),len(models)))\n",
    "for i in range(len(y_val)):\n",
    "    for j in range(len(models)):\n",
    "        val_predictions[i,j] = compute_prediction(x_val[i], y_val[i], models[j])\n",
    "        \n",
    "# convert from +/-1 to the original class \n",
    "for i in range(val_predictions.shape[0]):\n",
    "    for j in range(val_predictions.shape[1]):\n",
    "        if val_predictions[i,j]==1:\n",
    "            val_predictions[i,j]=all_pairs[j,0]\n",
    "        else:\n",
    "            val_predictions[i,j]=all_pairs[j,1]\n",
    "            \n",
    "# for each data point, pick either the most occurring prediction by all the classifiers or, if tie, random between\n",
    "# the tied classes\n",
    "val_prediction_results = []\n",
    "for i in range(len(val_predictions)):\n",
    "    freq = []\n",
    "    for j in class_possibilities:\n",
    "        freq.append(countX(list(val_predictions[i]),class_possibilities[j]))\n",
    "    prediction = class_possibilities[choice([k for k,x in enumerate(freq) if x==max(freq)])]\n",
    "    val_prediction_results.append(prediction)\n",
    "    \n",
    "freq = []\n",
    "for i in class_possibilities:\n",
    "    freq.append(countX(val_prediction_results,class_possibilities[i]))\n",
    "    \n",
    "# show results\n",
    "pd.DataFrame({'Class Indicator': class_possibilities, 'Freq': freq})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misclassification on the test set\n",
    "print('Validation Misclassificaiton Rate: ',np.mean(val_prediction_results != y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_conf_matrix = confusion_matrix(y_val, val_prediction_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = val_conf_matrix\n",
    "df_cm = pd.DataFrame(array, index = class_possibilities,\n",
    "                  columns = class_possibilities)\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt = 'g')# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fscore, support = precision_recall_fscore_support(y_val, val_prediction_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Class': class_possibilities,\n",
    "             'Training Pecision': precision,\n",
    "             'Training Recall': recall,})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write files to csv for competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = np.zeros((len(y_val),len(models)))\n",
    "for i in range(len(y_val)):\n",
    "    for j in range(len(models)):\n",
    "        test_predictions[i,j] = compute_prediction(x_test[i], y_val[i], models[j]) # y isn't used in the function\n",
    "        \n",
    "# convert from +/-1 to the original class \n",
    "for i in range(test_predictions.shape[0]):\n",
    "    for j in range(test_predictions.shape[1]):\n",
    "        if test_predictions[i,j]==1:\n",
    "            test_predictions[i,j]=all_pairs[j,0]\n",
    "        else:\n",
    "            test_predictions[i,j]=all_pairs[j,1]\n",
    "            \n",
    "# for each data point, pick either the most occurring prediction by all the classifiers or, if tie, random between\n",
    "# the tied classes\n",
    "test_prediction_results = []\n",
    "for i in range(len(test_predictions)):\n",
    "    freq = []\n",
    "    for j in class_possibilities:\n",
    "        freq.append(countX(list(test_predictions[i]),class_possibilities[j]))\n",
    "    prediction = class_possibilities[choice([k for k,x in enumerate(freq) if x==max(freq)])]\n",
    "    test_prediction_results.append(prediction)\n",
    "    \n",
    "freq = []\n",
    "for i in class_possibilities:\n",
    "    freq.append(countX(test_prediction_results,class_possibilities[i]))\n",
    "    \n",
    "# show results\n",
    "pd.DataFrame({'Class Indicator': class_possibilities, 'Freq': freq})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submission = pd.DataFrame({'Id':range(1000),'Category':test_prediction_results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submission.to_csv('willWright_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kaggle's Score: 73.67%** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 6 - Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick two classes of your choice from the dataset. Train an $\\ell_2^2$-regularized logistic regression classifier on the training set using your own fast gradient algorithm with $\\lambda = 1$. Plot, with different colors, the misclassification error on the training set and on the validation set vs iterations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the value of the regularization parameter $\\lambda$ using cross-validation; you may use\n",
    "scikit-learn’s built-in functions for this purpose. Train an $\\ell_2^2$ -regularized logistic regression classifier on the training set using your own fast gradient algorithm with that value of $\\lambda$ found by cross-validation. Plot, with different colors, the misclassification error on the training set and on the validation set vs iterations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 7 - Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you are going to train support vector machines (SVMs) using the data competition 2 project dataset (with 100 classes). You will consider here all classes in the dataset. You may work on this exercise on your own computer first. Note, however, that you need AWS to run the experiments for this entire exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you are going to train support vector machines (SVMs) using the data competition 2 project dataset (with 100 classes). You will consider here all classes in the dataset. You may work on this exercise on your own computer first. Note, however, that you need AWS to run the experiments for this entire exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**  \n",
    "In a one-vs-one fashion, for each pair of classes, train a linear SVM classifier using scikitlearn’s function LinearSVC, with the default value for the regularization parameter. Compute the _multi-class_ _misclassification error_ obtained using these classifiers trained in a one-vs-one fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (Windows)\n",
    "x_train_raw = np.load('C:/Users/Will/Documents/data_competition2_files/train_features.npy')\n",
    "y_train_raw = np.load('C:/Users/Will/Documents/data_competition2_files/train_labels.npy')\n",
    "x_val_raw = np.load('C:/Users/Will/Documents/data_competition2_files/val_features.npy')\n",
    "y_val_raw = np.load('C:/Users/Will/Documents/data_competition2_files/val_labels.npy')\n",
    "x_test_raw = np.load('C:/Users/Will/Documents/data_competition2_files/test_features.npy')\n",
    "\n",
    "# # Load data (Mac)\n",
    "# x_train_raw = np.load('/Users/willwright/Downloads/data558spring2019-competition2/train_features.npy')\n",
    "# y_train_raw = np.load('/Users/willwright/Downloads/data558spring2019-competition2/train_labels.npy')\n",
    "# x_val_raw = np.load('/Users/willwright/Downloads/data558spring2019-competition2/val_features.npy')\n",
    "# y_val_raw = np.load('/Users/willwright/Downloads/data558spring2019-competition2/val_labels.npy')\n",
    "# x_test_raw = np.load('/Users/willwright/Downloads/data558spring2019-competition2/test_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize x\n",
    "x_standardizer = preprocessing.StandardScaler()\n",
    "x_train = x_standardizer.fit_transform(x_train_raw)\n",
    "x_val = x_standardizer.fit_transform(x_val_raw)\n",
    "x_test = x_standardizer.fit_transform(x_test_raw)\n",
    "\n",
    "# No further processing needed for y\n",
    "y_train = y_train_raw\n",
    "y_val = y_val_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneVsOne_pred = OneVsOneClassifier(\n",
    "    LinearSVC(random_state=0, tol=1e-5, fit_intercept=False\n",
    "             )).fit(x_train,y_train).predict(x_val)\n",
    "\n",
    "np.mean(OneVsOne_pred==y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**  \n",
    "In a one-vs-rest fashion, for each class, train a linear SVM classifier using scikit-learn’s function LinearSVC, with the default value for $\\lambda_c$. Compute the multi-class misclassification error obtained using these classifiers trained in a one-vs-rest fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneVsRest_pred = OneVsRestClassifier(\n",
    "    LinearSVC(random_state=0, tol=1e-5, fit_intercept=False\n",
    "             )).fit(x_train[:10000,:],y_train[:10000]).predict(x_val[:2000,:])\n",
    "\n",
    "np.mean(OneVsRest_pred==y_val[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments** \n",
    "It took 1m41s to classify 10 categories with 10,000 samples and 51m17s to do 20 categories with 20,000 samples.  Given what seems to be an exponential growth, I'll need AWS to do the full 50,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneVsOne_kaggle_pred = OneVsOneClassifier(\n",
    "    LinearSVC(random_state=0, tol=1e-5, fit_intercept=False\n",
    "             )).fit(x_train,y_train).predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submission = pd.DataFrame({'Id':range(10000),'Category':OneVsOne_kaggle_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submission.to_csv('willWright_competition2_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle gives this a 55.5566% accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**  \n",
    "Redo all questions above now using your own code for the linear SVMs from Exercise 1. Make to sure to run preliminary experiments to decide how to set the stopping criterion to a value that allows the experiments to complete in a reasonable amount of time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
